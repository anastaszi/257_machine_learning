{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW10 Anastasia Zimina.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anastaszi/257_machine_learning/blob/master/HW10_Anastasia_Zimina.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6VYQGE3kfxsw"
      },
      "source": [
        "# Library Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAwKgZHKgVZE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d96a5941-55d7-48f9-93c0-1e992663dcd5"
      },
      "source": [
        "!pip install --upgrade gensim\n",
        "!pip install pyspellchecker \n",
        "!pip install contractions"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (4.1.2)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.4.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (5.2.1)\n",
            "Requirement already satisfied: pyspellchecker in /usr/local/lib/python3.7/dist-packages (0.6.2)\n",
            "Requirement already satisfied: contractions in /usr/local/lib/python3.7/dist-packages (0.0.58)\n",
            "Requirement already satisfied: textsearch>=0.0.21 in /usr/local/lib/python3.7/dist-packages (from contractions) (0.0.21)\n",
            "Requirement already satisfied: anyascii in /usr/local/lib/python3.7/dist-packages (from textsearch>=0.0.21->contractions) (0.3.0)\n",
            "Requirement already satisfied: pyahocorasick in /usr/local/lib/python3.7/dist-packages (from textsearch>=0.0.21->contractions) (1.4.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJToVgqdd9xs"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import re\n",
        "import string\n",
        "import wordcloud\n",
        "import nltk\n",
        "import unicodedata\n",
        "import contractions\n",
        "import pickle\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7OmGCCfgAhq",
        "outputId": "f036b3f3-1ed2-464b-a0ed-d15044ba613a"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from pandas.api.types import CategoricalDtype\n",
        "\n",
        "from gensim.utils import simple_preprocess\n",
        "from collections import defaultdict\n",
        "from contractions import contractions_dict\n",
        "from spellchecker import SpellChecker\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "from nltk.tokenize.toktok import ToktokTokenizer\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('universal_tagset')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "from contractions import contractions_dict\n",
        "from scipy import stats\n",
        "from scipy import sparse\n",
        "\n",
        "tokenizer = ToktokTokenizer()\n",
        "stopword_list = nltk.corpus.stopwords.words('english')\n",
        "scaler = MinMaxScaler()\n",
        "std_scaler = StandardScaler()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n",
            "[nltk_data]   Package universal_tagset is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dRsPZ0W7gGAo",
        "outputId": "04d069bf-75cd-4a7d-8032-760d77ad07f2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOo7uWyEeEbR"
      },
      "source": [
        "# Part I"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRUUD7wEd-mI"
      },
      "source": [
        "1. data ingestion and data prep : get  your 3 datasets\n",
        "2. train your microfactors/factor:  based on the latest datasets you have scraped or used an api\n",
        "3. save the trained model\n",
        "4. factor inference : run predictions on your factor and store the results of the inference\n",
        "5. classify the new data you brought in between 1-6 (true-o-meter ) classification based on politifact labels\n",
        "6. compare results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JpoW3NtUUtk7"
      },
      "source": [
        "## Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgPTt4_vU0LG"
      },
      "source": [
        "\n",
        "\n",
        "*   LiarLiarDataset [Article](https://arxiv.org/abs/1705.00648) [Repo](https://sites.cs.ucsb.edu/~william/data/)\n",
        "*   [Kaggle Fake News Corpus](https://www.kaggle.com/c/fake-news/data?select=train.csv)\n",
        "*   GossipCop [FakeNewsNetRepo](https://github.com/KaiDMML/FakeNewsNet)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vwvodHZBgVQf"
      },
      "source": [
        "### Dataset LiarLiar\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9YoUOgso2sSh"
      },
      "source": [
        "df_ll = pd.read_csv('/content/drive/MyDrive/ML/AlternusVera-Datasets/LiarLiar_datasets/liarliartrain.tsv', delimiter='\\t', dtype=object)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vy4UMpx05laP"
      },
      "source": [
        "df_ll.columns =['id', 'label', 'statement', 'subjects', 'speaker', 'speaker_job_title', 'state_info',  'party_affiliation', 'count_1', 'count_2','count_3','count_4','count_5','context' ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "id": "pGw0sG-53iER",
        "outputId": "2a3a1b36-dd43-4d44-ae0c-fc1d931444a9"
      },
      "source": [
        "df_ll.head(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>statement</th>\n",
              "      <th>subjects</th>\n",
              "      <th>speaker</th>\n",
              "      <th>speaker_job_title</th>\n",
              "      <th>state_info</th>\n",
              "      <th>party_affiliation</th>\n",
              "      <th>count_1</th>\n",
              "      <th>count_2</th>\n",
              "      <th>count_3</th>\n",
              "      <th>count_4</th>\n",
              "      <th>count_5</th>\n",
              "      <th>context</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10540.json</td>\n",
              "      <td>half-true</td>\n",
              "      <td>When did the decline of coal start? It started...</td>\n",
              "      <td>energy,history,job-accomplishments</td>\n",
              "      <td>scott-surovell</td>\n",
              "      <td>State delegate</td>\n",
              "      <td>Virginia</td>\n",
              "      <td>democrat</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>a floor speech.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           id      label  ... count_5          context\n",
              "0  10540.json  half-true  ...       0  a floor speech.\n",
              "\n",
              "[1 rows x 14 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2JlaXw8AJGqf",
        "outputId": "1a47f3d5-d222-4a53-919a-aa0125bf2ecd"
      },
      "source": [
        "df_ll['label'].unique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['half-true', 'mostly-true', 'false', 'true', 'barely-true',\n",
              "       'pants-fire'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eQPXx-pH6Lh"
      },
      "source": [
        "def conver_to_spam_metric(x):\n",
        "  label = x['label']\n",
        "  if (label == 'mostly-true' or label == 'true' or label == 'half-true'):\n",
        "    return 0\n",
        "  return 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uka3gIn6BzdY"
      },
      "source": [
        "df_ll['spam_label'] = df_ll.apply(conver_to_spam_metric, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "id": "K_1PGC5-MhtM",
        "outputId": "9a690466-728e-4c32-d033-d97f1263ef50"
      },
      "source": [
        "df_ll.head(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>statement</th>\n",
              "      <th>subjects</th>\n",
              "      <th>speaker</th>\n",
              "      <th>speaker_job_title</th>\n",
              "      <th>state_info</th>\n",
              "      <th>party_affiliation</th>\n",
              "      <th>count_1</th>\n",
              "      <th>count_2</th>\n",
              "      <th>count_3</th>\n",
              "      <th>count_4</th>\n",
              "      <th>count_5</th>\n",
              "      <th>context</th>\n",
              "      <th>spam_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10540.json</td>\n",
              "      <td>half-true</td>\n",
              "      <td>When did the decline of coal start? It started...</td>\n",
              "      <td>energy,history,job-accomplishments</td>\n",
              "      <td>scott-surovell</td>\n",
              "      <td>State delegate</td>\n",
              "      <td>Virginia</td>\n",
              "      <td>democrat</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>a floor speech.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           id      label  ...          context spam_label\n",
              "0  10540.json  half-true  ...  a floor speech.          0\n",
              "\n",
              "[1 rows x 15 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmMOt0YaMo9D"
      },
      "source": [
        "df_ll_new = df_ll[['statement', 'spam_label']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "E-pWsh2XM18u",
        "outputId": "db3a5a8d-a5d0-4224-9273-b3d1eb2e833d"
      },
      "source": [
        "df_ll_new.head(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>statement</th>\n",
              "      <th>spam_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>When did the decline of coal start? It started...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           statement  spam_label\n",
              "0  When did the decline of coal start? It started...           0"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qs23p1t0gbZv"
      },
      "source": [
        "### Dataset FakeNews\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYhUkw_TzhVl"
      },
      "source": [
        "df_fn = pd.read_csv('/content/drive/MyDrive/ML/AlternusVera-Datasets/Fake_news_kaggle_datasets/train.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-RGgxj5h05x5",
        "outputId": "9a5bd6a3-6e49-47e7-c613-69fc959d29ff"
      },
      "source": [
        "df_fn.head(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>title</th>\n",
              "      <th>author</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
              "      <td>Darrell Lucus</td>\n",
              "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  ... label\n",
              "0   0  ...     1\n",
              "\n",
              "[1 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWmM_-t00lum"
      },
      "source": [
        "df_fn = df_fn[['title', 'label']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ep670J3QO6-8"
      },
      "source": [
        "df_fn.rename(columns={'title': 'statement', 'label': 'spam_label'}, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbuyT_rT03uS",
        "outputId": "90711c3e-5567-41bc-8b48-1b6cb9e37fc7"
      },
      "source": [
        "df_fn.head(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>statement</th>\n",
              "      <th>spam_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           statement  spam_label\n",
              "0  House Dem Aide: We Didn’t Even See Comey’s Let...           1"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DyHHRQAKUJu3"
      },
      "source": [
        "### Dataset: GossipCap"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3EsY52AqOGJV"
      },
      "source": [
        "Fake news from GossipCap"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2s67eC1LNOLa"
      },
      "source": [
        "df_gc_f = pd.read_csv('/content/drive/MyDrive/ML/AlternusVera-Datasets/GossipCopDataset/master_dataset_gossipcop_fake.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jUfx5L-XNaOg",
        "outputId": "3c14c6f4-4cf2-44d1-9810-5c664b610afd"
      },
      "source": [
        "df_gc_f.head(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>news_url</th>\n",
              "      <th>title</th>\n",
              "      <th>tweet_ids</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>gossipcop-2493749932</td>\n",
              "      <td>www.dailymail.co.uk/tvshowbiz/article-5874213/...</td>\n",
              "      <td>Did Miley Cyrus and Liam Hemsworth secretly ge...</td>\n",
              "      <td>284329075902926848\\t284332744559968256\\t284335...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     id  ...                                          tweet_ids\n",
              "0  gossipcop-2493749932  ...  284329075902926848\\t284332744559968256\\t284335...\n",
              "\n",
              "[1 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3yHQA0isNfzV"
      },
      "source": [
        "df_gc_f['spam_label'] = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xC-GiYmkNqPo"
      },
      "source": [
        "df_gc_f.drop(['id', 'news_url', 'tweet_ids'], axis=1, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbYaLywJN1Cn",
        "outputId": "67c0d409-c881-4bf4-b84f-f8ba84044d89"
      },
      "source": [
        "df_gc_f.head(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>spam_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Did Miley Cyrus and Liam Hemsworth secretly ge...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               title  spam_label\n",
              "0  Did Miley Cyrus and Liam Hemsworth secretly ge...           1"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YW6p1yW5N8wr"
      },
      "source": [
        "df_gc_f.rename(columns={'title': 'statement'}, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ow1bKzeOE1F"
      },
      "source": [
        "df_gc_t = pd.read_csv('/content/drive/MyDrive/ML/AlternusVera-Datasets/GossipCopDataset/master_dataset_gossipcop_real.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LV7YqZyOSIH"
      },
      "source": [
        "df_gc_t['spam_label'] = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmppwH_eOVoE"
      },
      "source": [
        "df_gc_t.drop(['id', 'news_url', 'tweet_ids'], axis=1, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_rUqa9VkObZB"
      },
      "source": [
        "df_gc_t.rename(columns={'title': 'statement'}, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cqgPaT3VOX0c",
        "outputId": "5d3864a3-be7e-4054-8f76-707c9057dddf"
      },
      "source": [
        "df_gc_t.head(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>statement</th>\n",
              "      <th>spam_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Teen Mom Star Jenelle Evans' Wedding Dress Is ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           statement  spam_label\n",
              "0  Teen Mom Star Jenelle Evans' Wedding Dress Is ...           0"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDVgHwOjO6s2"
      },
      "source": [
        "### Combine all datasets together"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYPzschSO9wC"
      },
      "source": [
        "df = df_ll_new.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_K4fd-4PEdO"
      },
      "source": [
        "df = df.append(df_fn, ignore_index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LpFufYfzPTat"
      },
      "source": [
        "df = df.append(df_gc_f, ignore_index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3wC2CPCPxgB"
      },
      "source": [
        "df = df.append(df_gc_t, ignore_index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LuPz7fDKP2RM",
        "outputId": "eb65a53f-32d8-4f57-bd56-22e89e731b4c"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(53179, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgLGkrEcP8ZE"
      },
      "source": [
        "df.to_csv('/content/drive/MyDrive/ML/AlternusVera-Datasets/spam_dataset_full.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LuDXHPReQtiu"
      },
      "source": [
        "## Data Prep"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "itbGLRJhQ7w1",
        "outputId": "07b3ae4a-71ae-4302-f920-e6142235ec23"
      },
      "source": [
        "df[df.isna().any(axis=1)]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>statement</th>\n",
              "      <th>spam_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120</th>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>124</th>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>140</th>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>196</th>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20568</th>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20627</th>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20636</th>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20771</th>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20772</th>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>558 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      statement  spam_label\n",
              "53          NaN           1\n",
              "120         NaN           1\n",
              "124         NaN           1\n",
              "140         NaN           1\n",
              "196         NaN           1\n",
              "...         ...         ...\n",
              "20568       NaN           1\n",
              "20627       NaN           1\n",
              "20636       NaN           1\n",
              "20771       NaN           1\n",
              "20772       NaN           1\n",
              "\n",
              "[558 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FC3gJZAPRB5Q"
      },
      "source": [
        "df = df.dropna();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jz_SrIgZRWh3"
      },
      "source": [
        "  def process_text(text):\n",
        "    def remove_accented_chars(text):\n",
        "      text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
        "      return text\n",
        "\n",
        "    def remove_stopwords(words, stopwords):\n",
        "      words = [w for w in  words  if not w in stopwords] \n",
        "      return words\n",
        "    def remove_smallwords(words):\n",
        "      words = [w for w in  words  if len(w)> 2] \n",
        "      return words\n",
        "\n",
        "    doc = remove_accented_chars(text)\n",
        "    # remove contractions\n",
        "    doc = contractions.fix(doc)\n",
        "    doc = doc.lower()\n",
        "    # remove new lines\n",
        "    doc = re.sub(r'[\\r|\\n|\\r\\n]+','', doc)\n",
        "    # remove extra white spaces\n",
        "    doc = re.sub(' +', ' ', doc)\n",
        "    # remove special characters\n",
        "    special_char_pattern = re.compile(r'([{.(-)!}])')\n",
        "    # leave only words\n",
        "    doc = re.sub('\\W+',' ', doc)\n",
        "    doc = re.sub(r'[^a-zA-Z\\s]', '', doc)\n",
        "    words = tokenizer.tokenize(doc)\n",
        "    words = [token.strip() for token in words]\n",
        "    # lemmatize\n",
        "    words = [ WordNetLemmatizer().lemmatize(w) for w in words ]\n",
        "    words = remove_stopwords(words, stopword_list)\n",
        "    words = remove_smallwords(words)\n",
        "    return words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "epNXlyt9SVIz"
      },
      "source": [
        "Tokenize statements into words:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fp7pvOwhRmvF"
      },
      "source": [
        "df['words'] = df['statement'].apply(process_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QG8hkQyOSgJD"
      },
      "source": [
        "def POS_count(words):\n",
        "  tagged_words = nltk.pos_tag(words, tagset='universal');\n",
        "  num_words = len(tagged_words)\n",
        "  fq= defaultdict( int )\n",
        "  for (word, pos) in tagged_words:\n",
        "    fq[pos] += 1\n",
        "  # share of nouns etc...\n",
        "  if num_words == 0:\n",
        "    return 0,0,0,0,0,0,0\n",
        "  nouns = fq['NOUN']/num_words\n",
        "  adjs = fq['ADJ'] /num_words\n",
        "  prep = (fq['ADP'] + fq['CONJ'])/num_words\n",
        "  dets = fq['DET']/num_words\n",
        "  vbs = fq['VERB']/num_words\n",
        "  advs = fq['ADV']/num_words\n",
        "  prons = fq['PRON']/num_words\n",
        "  return nouns, adjs, prep, dets, vbs, advs, prons"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W5N5OG1mSnqf"
      },
      "source": [
        "- 'noun' = Noun,\n",
        "- 'adj' = Adjective,\n",
        "- 'prep' = Adposition and conjunction,\n",
        "- 'dt' = Determiner,\n",
        "- 'verb' = Verb,\n",
        "- 'adv' = Adverb,\n",
        "- 'pron' = Pronoun"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ak8ogjYzSkQh"
      },
      "source": [
        "df['noun'], df['adj'], df['prep'], df['dt'], df['verb'], df['adv'], df['pron'] = zip(*df['words'].map(POS_count))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5vFvVtrSyFz"
      },
      "source": [
        "spell = SpellChecker()\n",
        "def count_misspelled(words):\n",
        "  misspelled = spell.unknown(words)\n",
        "  return len(misspelled)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BhsdrcuuS1NJ"
      },
      "source": [
        "df['count_mis'] = df.apply(lambda x: count_misspelled(x['words']), axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItUUwFw4S7W5"
      },
      "source": [
        "df.to_csv(\"/content/drive/MyDrive/ML/AlternusVera-Datasets/spam_dataset_processed_full.csv', index=False\", sep=',')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltTl2YbHTIRh"
      },
      "source": [
        "X = df.drop('spam_label', axis=1)\n",
        "y = df['spam_label']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pg7CEJ3oTTDf"
      },
      "source": [
        "tfidf = TfidfVectorizer(preprocessor=lambda x: x, tokenizer=lambda x: x)\n",
        "X_train_tfidf_features = tfidf.fit_transform(X_train['words'])\n",
        "X_test_tfidf_features = tfidf.transform(X_test['words'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2szPXLaQTlAE"
      },
      "source": [
        "tf_transformer_vocab = tfidf.vocabulary_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YHhqfP7-Tn4K",
        "outputId": "b10b1b02-46a3-40e1-e8b1-c9ea727d60fc"
      },
      "source": [
        "print('TFIDF model:> Train features shape:', X_train_tfidf_features.shape, 'TFIDF model:> Test features shape:', X_test_tfidf_features.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TFIDF model:> Train features shape: (35256, 23918) TFIDF model:> Test features shape: (17365, 23918)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrkcSg0eTVTF"
      },
      "source": [
        "## Model Training Spam Score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDYk7eFQTsbg"
      },
      "source": [
        "classifiers = []\n",
        "classifiers.append(('Multinomial NB', MultinomialNB(alpha=1)))\n",
        "# classifiers.append((\"Logistic Regression\", LogisticRegression(random_state=42)))\n",
        "# classifiers.append((\"RandomForestClassifier\", RandomForestClassifier(random_state=42)))\n",
        "\n",
        "results = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Z5nvs0wTvR8"
      },
      "source": [
        "def model_loop(models, X_train, X_test, y_train, y_test, factor, results):\n",
        "  trained_models=[]\n",
        "  for (name, model) in models:\n",
        "    model.fit(X_train, y_train)\n",
        "    cv_scores = cross_val_score(model, X_train, y_train, cv=5)\n",
        "    cv_mean_score = np.mean(cv_scores)\n",
        "    test_score = model.score(X_test, y_test)\n",
        "    results.append([factor, name, cv_scores, cv_mean_score, test_score])\n",
        "    trained_models.append((name, model))\n",
        "  return trained_models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8mKxDcdTU8g"
      },
      "source": [
        "pos_columns = [\"noun\",\"adj\",\"prep\",\t\"dt\", \"verb\",\t\"adv\"]\n",
        "X_train_pos_features = scaler.fit_transform(X_train[pos_columns])\n",
        "X_test_pos_features = scaler.fit_transform(X_test[pos_columns])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42fC7PyUUALL"
      },
      "source": [
        "X_train_spell_features = scaler.fit_transform(X_train[['count_mis']])\n",
        "X_test_spell_features = scaler.fit_transform(X_test[['count_mis']])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7jkqKDqT8i9"
      },
      "source": [
        "X_train_spam = sparse.hstack([X_train_tfidf_features, X_train_spell_features, X_train_pos_features]).tocsr()\n",
        "X_test_spam  = sparse.hstack([X_test_tfidf_features, X_test_spell_features, X_test_pos_features]).tocsr()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVB4n21BUNYw"
      },
      "source": [
        "spam_models = model_loop(classifiers, X_train_spam, X_test_spam, y_train, y_test, 'SPAM', results);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "Fv4SmoEXUS5t",
        "outputId": "d704f729-3e67-4479-a84d-62ef562ee550"
      },
      "source": [
        "df_results = pd.DataFrame(results, columns=['Factor', 'Model', 'CV Accuracy (5-fold)', 'Mean CV Accuracy', 'Test Accuracy'])\n",
        "df_results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Factor</th>\n",
              "      <th>Model</th>\n",
              "      <th>CV Accuracy (5-fold)</th>\n",
              "      <th>Mean CV Accuracy</th>\n",
              "      <th>Test Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>SPAM</td>\n",
              "      <td>Multinomial NB</td>\n",
              "      <td>[0.7492909812819059, 0.7519500780031201, 0.750...</td>\n",
              "      <td>0.751135</td>\n",
              "      <td>0.755428</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Factor           Model  ... Mean CV Accuracy  Test Accuracy\n",
              "0   SPAM  Multinomial NB  ...         0.751135       0.755428\n",
              "\n",
              "[1 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbDSMEl7Uyse"
      },
      "source": [
        "pickle.dump(tfidf.vocabulary_, open(\"/content/drive/MyDrive/ML/FEATURE_MODELS/tfidf_vocab.pkl\", \"wb\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLcBEKqVU1An"
      },
      "source": [
        "pickle.dump(spam_models[0][1], open(\"/content/drive/MyDrive/ML/FEATURE_MODELS/spam_model.pkl\", \"wb\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJvMmZhRYYCx"
      },
      "source": [
        "## Model Training Classification\n",
        "\n",
        "> Indented block\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ovMsLr7hECO"
      },
      "source": [
        "### Politifact dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOHAKnQZhGk1"
      },
      "source": [
        "df_poli = pd.read_csv('/content/drive/MyDrive/ML/AlternusVera-Datasets/scraped_data.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "run4vuVBhPm9",
        "outputId": "609125dc-144a-4344-a5ad-f730cb0e1a3f"
      },
      "source": [
        "df_poli.head(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>author</th>\n",
              "      <th>statement</th>\n",
              "      <th>source</th>\n",
              "      <th>date</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Kiannah Sepeda-Miller</td>\n",
              "      <td>The migrant caravan from Tapachula, Mexico “is...</td>\n",
              "      <td>Mary Miller</td>\n",
              "      <td>October 31, 2021</td>\n",
              "      <td>pants-fire</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  author  ...      target\n",
              "0  Kiannah Sepeda-Miller  ...  pants-fire\n",
              "\n",
              "[1 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "OwvvfS-BicCA",
        "outputId": "f9ff942f-2f12-4b08-e308-3378a16e6e3c"
      },
      "source": [
        "df_poli.groupby('target').count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>author</th>\n",
              "      <th>statement</th>\n",
              "      <th>source</th>\n",
              "      <th>date</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>target</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>barely-true</th>\n",
              "      <td>346</td>\n",
              "      <td>346</td>\n",
              "      <td>346</td>\n",
              "      <td>346</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>false</th>\n",
              "      <td>1165</td>\n",
              "      <td>1165</td>\n",
              "      <td>1165</td>\n",
              "      <td>1165</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>full-flop</th>\n",
              "      <td>13</td>\n",
              "      <td>13</td>\n",
              "      <td>13</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>half-flip</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>half-true</th>\n",
              "      <td>223</td>\n",
              "      <td>223</td>\n",
              "      <td>223</td>\n",
              "      <td>223</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mostly-true</th>\n",
              "      <td>137</td>\n",
              "      <td>137</td>\n",
              "      <td>137</td>\n",
              "      <td>137</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>no-flip</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pants-fire</th>\n",
              "      <td>417</td>\n",
              "      <td>417</td>\n",
              "      <td>417</td>\n",
              "      <td>417</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>true</th>\n",
              "      <td>94</td>\n",
              "      <td>94</td>\n",
              "      <td>94</td>\n",
              "      <td>94</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             author  statement  source  date\n",
              "target                                      \n",
              "barely-true     346        346     346   346\n",
              "false          1165       1165    1165  1165\n",
              "full-flop        13         13      13    13\n",
              "half-flip         4          4       4     4\n",
              "half-true       223        223     223   223\n",
              "mostly-true     137        137     137   137\n",
              "no-flip           1          1       1     1\n",
              "pants-fire      417        417     417   417\n",
              "true             94         94      94    94"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "auN_1Hi4hdc5",
        "outputId": "85a50ab6-2ab9-4b00-b87c-8706e7353b89"
      },
      "source": [
        "df_poli['target'].unique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['pants-fire', 'false', 'barely-true', 'mostly-true', 'true',\n",
              "       'half-true', 'half-flip', 'full-flop', 'no-flip'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vs4Ov-TWkBN0"
      },
      "source": [
        "df_poli.drop(df_poli[df_poli['target'] == 'half-flip'].index, inplace = True)\n",
        "df_poli.drop(df_poli[df_poli['target'] == 'full-flop'].index, inplace = True)\n",
        "df_poli.drop(df_poli[df_poli['target'] == 'no-flip'].index, inplace = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VRv0dXBclqRR",
        "outputId": "640a895b-78b4-4971-f887-d7c5631738d1"
      },
      "source": [
        "df_poli.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2382, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRX9vUCHsW-e"
      },
      "source": [
        "cat_type = CategoricalDtype(categories=[\"true\", \"mostly-true\", \"half-true\", 'barely-true', 'false', 'pants-fire'], ordered=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SoNAQJfDruF4"
      },
      "source": [
        "df_poli['label'] = df_poli['target'].astype(cat_type)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tq9HvMX6t8tg"
      },
      "source": [
        "df_poli.drop(['author', 'source', 'date', 'target'], axis=1,inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "8zhd3CzIszkm",
        "outputId": "bbb25d17-a789-41e3-f13c-5e50e32ed47a"
      },
      "source": [
        "df_poli.head(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>statement</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The migrant caravan from Tapachula, Mexico “is...</td>\n",
              "      <td>pants-fire</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           statement       label\n",
              "0  The migrant caravan from Tapachula, Mexico “is...  pants-fire"
            ]
          },
          "metadata": {},
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GXrqzgAItz51"
      },
      "source": [
        "### Predict spam score for politifact dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IzCWSvs-uIs-"
      },
      "source": [
        "tf_vocab = pickle.load(open(\"/content/drive/MyDrive/ML/FEATURE_MODELS/tfidf_vocab.pkl\", 'rb'))\n",
        "spam_model = pickle.load(open(\"/content/drive/MyDrive/ML/FEATURE_MODELS/spam_model.pkl\", 'rb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CW_ALIKHYWSS"
      },
      "source": [
        "class Spam():\n",
        "\n",
        "  def POS_count(self, words):\n",
        "    tagged_words = nltk.pos_tag(words, tagset='universal');\n",
        "    num_words = len(tagged_words)\n",
        "    fq= defaultdict( int )\n",
        "    for (word, pos) in tagged_words:\n",
        "      fq[pos] += 1\n",
        "    # share of nouns etc...\n",
        "    if num_words == 0:\n",
        "      return 0,0,0,0,0,0,0\n",
        "    nouns = fq['NOUN']/num_words\n",
        "    adjs = fq['ADJ'] /num_words\n",
        "    prep = (fq['ADP'] + fq['CONJ'])/num_words\n",
        "    dets = fq['DET']/num_words\n",
        "    vbs = fq['VERB']/num_words\n",
        "    advs = fq['ADV']/num_words\n",
        "    prons = fq['PRON']/num_words\n",
        "    return nouns, adjs, prep, dets, vbs, advs, prons\n",
        "  def remove_accented_chars(self, text):\n",
        "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
        "    return text\n",
        "  \n",
        "  def remove_stopwords(self, words, stopwords):\n",
        "    words = [w for w in  words  if not w in stopwords] \n",
        "    return words\n",
        "\n",
        "  def remove_smallwords(self,words):\n",
        "    words = [w for w in  words  if len(w)> 2] \n",
        "    return words\n",
        "\n",
        "  def process_text(self, text):\n",
        "    custom_stopwords = self.custom_stopwords\n",
        "    doc = self.remove_accented_chars(text)\n",
        "    # remove contractions\n",
        "    doc = contractions.fix(doc)\n",
        "    doc = doc.lower()\n",
        "    # remove new lines\n",
        "    doc = re.sub(r'[\\r|\\n|\\r\\n]+','', doc)\n",
        "    # remove extra white spaces\n",
        "    doc = re.sub(' +', ' ', doc)\n",
        "    # remove special characters\n",
        "    special_char_pattern = re.compile(r'([{.(-)!}])')\n",
        "    # leave only words\n",
        "    doc = re.sub('\\W+',' ', doc)\n",
        "    doc = re.sub(r'[^a-zA-Z\\s]', '', doc)\n",
        "    words = tokenizer.tokenize(doc)\n",
        "    words = [token.strip() for token in words]\n",
        "    # lemmatize\n",
        "    words = [ WordNetLemmatizer().lemmatize(w) for w in words ]\n",
        "    words = self.remove_stopwords(words, custom_stopwords)\n",
        "    words = self.remove_smallwords(words)\n",
        "    return words\n",
        "\n",
        "  def __init__(self, model, tf_vocab_):\n",
        "    self.model = model\n",
        "    self.custom_stopwords = stopword_list + ['wa', 'mr']\n",
        "    self.sc = MinMaxScaler()\n",
        "    self.pos_columns = [\"noun\",\"adj\",\"prep\",\t\"dt\", \"verb\",\t\"adv\"]\n",
        "    self.spell = SpellChecker()\n",
        "    self.tfidf = TfidfVectorizer(preprocessor=lambda x: x, tokenizer=lambda x: x,analyzer='word', vocabulary = tf_vocab_)\n",
        "  \n",
        "  def count_misspelled(self,words):\n",
        "    misspelled = self.spell.unknown(words)\n",
        "    return len(misspelled)\n",
        "  \n",
        "  def create_df(self, text):\n",
        "    dfrme = pd.DataFrame(index=[0], columns=['text'])\n",
        "    dfrme['text'] = text\n",
        "    dfrme['words'] = dfrme['text'].apply(self.process_text)\n",
        "    return dfrme\n",
        "  \n",
        "  def predict_spam(self, text):\n",
        "    dfrme = self.create_df(text)\n",
        "    dfrme['noun'], dfrme['adj'], dfrme['prep'], dfrme['dt'], dfrme['verb'], dfrme['adv'], dfrme['pron'] = zip(*dfrme['words'].map(self.POS_count))\n",
        "    dfrme['count_mis'] = dfrme.apply(lambda x: self.count_misspelled(x['words']), axis=1)\n",
        "    spell_features = self.sc.fit_transform(dfrme[['count_mis']])\n",
        "    pos_features = self.sc.fit_transform(dfrme[self.pos_columns])\n",
        "    tfidf_features = self.tfidf.fit_transform(dfrme['words'])\n",
        "    combined_features = sparse.hstack([spell_features, pos_features, tfidf_features]).tocsr()\n",
        "    prediced = self.model.predict(combined_features)\n",
        "    predicedProb = self.model.predict_proba(combined_features)\n",
        "    return (prediced[0], predicedProb[0][1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nkGe8QJlukUr"
      },
      "source": [
        "spam = Spam(spam_model, tf_vocab)\n",
        "def CLIMATEFRIENDS_getSpamScore(text):  # return between 0 and 1, being 0 = True,  1 = Fake\n",
        "    binaryValue, probValue = spam.predict_spam(text)\n",
        "    return probValue"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAMWXVMDvHZ0"
      },
      "source": [
        "df_poli['spam_score'] = df_poli['statement'].apply(CLIMATEFRIENDS_getSpamScore)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ah_jxGxKvt7f"
      },
      "source": [
        "df_poli.to_csv(\"/content/drive/MyDrive/ML/AlternusVera-Datasets/spam_politifact_dataset_processed_full.csv', index=False\", sep=',')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMyLkvIZ548I"
      },
      "source": [
        "poli_classifiers = []\n",
        "poli_classifiers.append((\"Logistic Regression\", LogisticRegression(random_state=42)))\n",
        "poli_classifiers.append((\"RandomForestClassifier\", RandomForestClassifier(random_state=42)))\n",
        "\n",
        "final_results = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1-Y7rx5EmCw"
      },
      "source": [
        "X_poli = df_poli.drop(['label', 'statement'], axis=1)\n",
        "y_poli = df_poli['label']\n",
        "X_poli_train, X_poli_test, y_poli_train, y_poli_test = train_test_split(X_poli, y_poli, test_size=0.33, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uyu7ivxNFUPM"
      },
      "source": [
        "poli_models = model_loop(poli_classifiers, X_poli_train, X_poli_test, y_poli_train, y_poli_test, 'Poli_classifier', final_results);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "bd3fN6GoGLvJ",
        "outputId": "b7e4ba66-d8fa-4c7c-b5d2-72688051cda3"
      },
      "source": [
        "df_poli_results = pd.DataFrame(final_results, columns=['Factor', 'Model', 'CV Accuracy (5-fold)', 'Mean CV Accuracy', 'Test Accuracy'])\n",
        "df_poli_results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Factor</th>\n",
              "      <th>Model</th>\n",
              "      <th>CV Accuracy (5-fold)</th>\n",
              "      <th>Mean CV Accuracy</th>\n",
              "      <th>Test Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Poli_classifier</td>\n",
              "      <td>Logistic Regression</td>\n",
              "      <td>[0.4952978056426332, 0.4952978056426332, 0.492...</td>\n",
              "      <td>0.493417</td>\n",
              "      <td>0.480305</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Poli_classifier</td>\n",
              "      <td>RandomForestClassifier</td>\n",
              "      <td>[0.30094043887147337, 0.3072100313479624, 0.23...</td>\n",
              "      <td>0.287774</td>\n",
              "      <td>0.320203</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Factor                   Model  ... Mean CV Accuracy  Test Accuracy\n",
              "0  Poli_classifier     Logistic Regression  ...         0.493417       0.480305\n",
              "1  Poli_classifier  RandomForestClassifier  ...         0.287774       0.320203\n",
              "\n",
              "[2 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kbTJK3KHEh3"
      },
      "source": [
        "pickle.dump(poli_models[0], open(\"/content/drive/MyDrive/ML/FEATURE_MODELS/poli_spam_classif_model.pkl\", \"wb\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T48nlEeUMN5U"
      },
      "source": [
        "text = df_poli[df_poli.label == 'true']['statement'].to_numpy()[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cxXLOP7ZMVY9",
        "outputId": "7edc472b-f969-4c4e-897b-801757720771"
      },
      "source": [
        "print(text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Biden administration \"published a study concluding 4 (of) 5 new cars on the road by 2050 will still require liquid fuels.\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtLD54nnHRBs"
      },
      "source": [
        "class PoliSpamClassif():\n",
        "  def __init__(self, model_spam_score, vocab, model_classif):\n",
        "    self.model_classif = model_classif\n",
        "    self.spam = Spam(model_spam_score, vocab)\n",
        "\n",
        "  def predict(self,text):\n",
        "    binaryValue, probValue = spam.predict_spam(text)\n",
        "    dfrme = pd.DataFrame(index=[0], columns=['spam_score'])\n",
        "    dfrme['spam_score'] = probValue\n",
        "    prediced = self.model_classif.predict(dfrme)\n",
        "    predicedProb = self.model_classif.predict_proba(dfrme)\n",
        "    print(predicedProb)\n",
        "    return prediced"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-346NXlKsKV"
      },
      "source": [
        "polispam = PoliSpamClassif(spam_model, tf_vocab, poli_models[0][1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Y9g23iQK7at",
        "outputId": "e1569fde-e982-4220-c44e-217777ae6e8f"
      },
      "source": [
        "polispam.predict(\"Migrants are crossing the border\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.144218   0.48549541 0.09073293 0.05958213 0.17953905 0.04043247]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['false'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ACpqb3HeK2B"
      },
      "source": [
        "# Part II\n",
        "\n",
        "team work in [this notebook](https://colab.research.google.com/drive/1u5lL8hOxaHcLR-j01CrKxpNCQaHbutcq#scrollTo=ZTWGIaNiCkzI)"
      ]
    }
  ]
}